{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook explores the all data processing steps in order from cleaning the raw data to generating the evaluation data template.\n",
    "\n",
    "We start with two csv files. One contains information about cocoa producers contained in a pdf released by the govenrmnet of Ivory Coast. The other contains information about cocoa producers collected from large cocoa importers (e.g. Ferrero, Olam, Nestle, ...). In order to merge the datasets, we need to find all possible row combinations between the CSVs which describe the same entity. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files into DataFrames\n",
    "cooperatives_1 = pd.read_csv('data/raw/ivorian-cocoa-coop-registry-2017.csv')\n",
    "cooperatives_2 = pd.read_csv('data/raw/cocoa-suppliers-compiled-from-importers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Look at Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cooperatives_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cooperatives_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis import plot_missingness\n",
    "\n",
    "# Plot missingness for each DataFrame\n",
    "print(f'cooperatives 1: {cooperatives_1.shape}')\n",
    "print(f'cooperatives 2: {cooperatives_2.shape}')\n",
    "plot_missingness(cooperatives_1, 'cooperatives_1')\n",
    "plot_missingness(cooperatives_2, 'cooperatives_2')\n",
    "\n",
    "# Calculate and print percentage of missing values for each DataFrame\n",
    "for name, df in [('cooperatives_1', cooperatives_1), ('cooperatives_2', cooperatives_2)]:\n",
    "    print(f\"\\nPercentage of missing values in {name}:\")\n",
    "    print(df.isnull().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "When cleaning, we first pass over the govrnment data specifically, then use a different function to clean both government and company data, `cooperatives_1` and `cooperatives_2` respectively. \n",
    "\n",
    "Government data only: \n",
    "1. Remove rows that contain only null values\n",
    "2. Rename columns to more descriptive names\n",
    "3. Extract the abbreviation (text inside parentheses) from 'Producer Name' and create a new column for it\n",
    "4. Remove the abbreviation text along with the parentheses from 'Producer Name'\n",
    "\n",
    "Process both: \n",
    "1. Remove rows where 'Producer Name' or 'Abbreviation Name' are None\n",
    "2. Clean the 'Producer Name' and 'Abbreviation Name' columns by forcing lower case, removing extra whitespace, normalizing unicode\n",
    "5. Drop the 'Country' column if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooperatives_1 = pd.read_csv('data/clean/ivorian-cocoa-coop-registry-2017.csv')\n",
    "cooperatives_2 = pd.read_csv('data/clean/cocoa-suppliers-compiled-from-importers.csv')\n",
    "\n",
    "# Plot missingness for each DataFrame\n",
    "print(f'cooperatives 1: {cooperatives_1.shape}')\n",
    "print(f'cooperatives 2: {cooperatives_2.shape}')\n",
    "plot_missingness(cooperatives_1, 'cooperatives_1')\n",
    "plot_missingness(cooperatives_2, 'cooperatives_2')\n",
    "\n",
    "# Calculate and print percentage of missing values for each DataFrame\n",
    "for name, df in [('cooperatives_1', cooperatives_1), ('cooperatives_2', cooperatives_2)]:\n",
    "    print(f\"\\nPercentage of missing values in {name}:\")\n",
    "    print(df.isnull().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are some null values left in `Region`, but it will not matter because it is not used in evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Name Pairs\n",
    "\n",
    "Name pairs are generated by taking the cartesian product between the two cleaned CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv('data/outputs/all_pairs.csv')\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Silarity Tests\n",
    "\n",
    "We use `paraphrase-MiniLM-L6-v2` from huggingface and TF-IDF vectorizer to embed the producer names and find each pair's cosine similarity. A high similarity should indicate a higher likelihood that the names represent the same entity. We define thresholds for each method and use the results to generate an eval set. These samples with high similarity will be more difficult to classify on average, and, thus, provide a good starting point for the eval set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pairs = pd.read_csv('data/outputs/pair_similarity.csv')\n",
    "processed_pairs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis import similarity_hist\n",
    "\n",
    "similarity_hist(\n",
    "    df=processed_pairs, \n",
    "    column='tf_idf_similarity_name', \n",
    "    title='Distribution of TF-IDF Similarity Scores', \n",
    "    threshold= 0.85\n",
    ")\n",
    "\n",
    "similarity_hist(\n",
    "    df=processed_pairs, \n",
    "    column='semantic_similarity_name', \n",
    "    title='Distribution of Semantic Similarity Scores Between Producer Names', \n",
    "    threshold= 0.85\n",
    ")\n",
    "\n",
    "similarity_hist(\n",
    "    df=processed_pairs, \n",
    "    column='second_half_similarity_name', \n",
    "    title='Distribution of Semantic Similarity Scores Between Second Half of Producer Names', \n",
    "    threshold= 0.85\n",
    ")\n",
    "\n",
    "similarity_hist(\n",
    "    df=processed_pairs, \n",
    "    column='second_half_weighted_similarity', \n",
    "    title='Distribution of Semantic Similarity Scores Weighing the Second Half More', \n",
    "    threshold= 0.85\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Pairs Ranked\n",
    "\n",
    "Change `column` to the column from `processed_pairs` that you want to sort by to explore.\n",
    "\n",
    "Your choices:\n",
    "1. `tf_idf_similarity_name`\n",
    "2. `semantic_similarity_name`\n",
    "3. `second_half_similarity_name`\n",
    "4. `second_half_weighted_similarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'semantic_similarity_name'\n",
    "processed_pairs = processed_pairs.sort_values(by=column, ascending=False)\n",
    "        \n",
    "for i in range(100):\n",
    "    row = processed_pairs.iloc[i]\n",
    "    print(f\"{row['Producer Name_x']:<50} | {row['Producer Name_y']:<50} | {row[column]:.4f} | {row['Abbreviation Name_x']:<10} | {row['Abbreviation Name_y']:<10} \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can notice immediately from `semantic_similarity_name` is that the way the string starts seems to heavily sway the similarity resulting similarity measure. This is why we create `second_half_similarity_name` and combine the aforementioned two to create `second_half_weighted_similarity`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Template\n",
    "\n",
    "We generate the evaluation data template by pulling the top 200 pairs ranked by `second_half_weighted_similarity` and `tf_idf_similarity_name`. The duplicate rows are removed and new column `classification` is added with all calsses set to 0 (false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_template = pd.read_csv('data/outputs/eval_template.csv')\n",
    "eval_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
